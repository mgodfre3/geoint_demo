apiVersion: apps/v1
kind: Deployment
metadata:
  name: vision-pipeline
  namespace: geoint-vision
  labels:
    app: vision-pipeline
spec:
  replicas: 1
  selector:
    matchLabels:
      app: vision-pipeline
  template:
    metadata:
      labels:
        app: vision-pipeline
    spec:
      containers:
        # Ollama â€” local LLM inference (replaces Foundry Local until container support ships)
        - name: ollama
          image: ollama/ollama:latest
          ports:
            - containerPort: 11434
          resources:
            limits:
              nvidia.com/gpu: "1"
              memory: "8Gi"
            requests:
              memory: "4Gi"
          volumeMounts:
            - name: ollama-data
              mountPath: /root/.ollama

        # YOLOv8 satellite object detection
        - name: yolov8-detector
          image: acrgeointdemo.azurecr.io/geoint/yolov8-satellite:latest
          ports:
            - containerPort: 8000
          resources:
            limits:
              memory: "4Gi"
            requests:
              memory: "2Gi"

        # FastAPI backend
        - name: api-backend
          image: acrgeointdemo.azurecr.io/geoint/vision-api:latest
          ports:
            - containerPort: 8082
          resources:
            limits:
              memory: "2Gi"
            requests:
              memory: "1Gi"
          env:
            - name: FOUNDRY_URL
              value: "http://localhost:11434"
            - name: YOLO_URL
              value: "http://localhost:8000"

        # React frontend
        - name: frontend
          image: acrgeointdemo.azurecr.io/geoint/vision-ui:latest
          ports:
            - containerPort: 80
          resources:
            limits:
              memory: "512Mi"
            requests:
              memory: "256Mi"

      volumes:
        - name: ollama-data
          emptyDir: {}
